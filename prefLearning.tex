\frameT{Outline}{
  \begin{enumerate}
    {\transparent{0.2} \item The languages of P-trees, PLP-trees, and LP-trees}
    \item Learning of preference models (PLP-trees and P-forests)
    {\transparent{0.2} \item Reasoning with preferences:
      \begin{itemize}
        \item Preference optimization in case of P-trees
        \item Computing winners and ``strong" outcomes when votes are LP-trees
        \item Application in trip planning
      \end{itemize}}
    {\transparent{0.2} \item Future research directions}
  \end{enumerate}
}

\frameT{Learning Problems on PLP-trees}{
	\begin{block}{Consistent Learning (\tsc{ConsLearn})}
		Given an example set $\cE$, decide 
		whether there exists a PLP-tree $T$ (of a particular type) such that $T$ 
		is consistent with $\cE$.
	\end{block}

	\begin{block}{Small Learning (\tsc{SmallLearn})}
		Given an example set $\cE$
		and a positive integer $l$ ($l \leq |\cE|$), decide whether there 
		exists a PLP-tree $T$ (of a particular type) such that $T$ is consistent 
		with $\cE$ and $|T| \leq l$.
	\end{block}

	\begin{block}{Maixmal Learning (\tsc{MaxLearn})}
		Given an example set $\cE$ and a 
		positive integer $k$ ($k \leq m$), decide whether there exists a PLP-tree 
		$T$ (of a particular type) such that $T$ satisfies at least $k$ examples 
		in $\cE$.
	\end{block}
}

\frameT{Computational Complexity}{
  \begin{enumerate}
    \item $P$, $\NP$, $\coNP$: We typically believe that $P \subset \NP$ and $P \subset \coNP$.
    %\item $\coNP$: problems whose complements are in $\NP$.
    \item $\deltap{2}$: $P^\NP$, $\sigmap{2}$: $\NP^\NP$, and $\pip{2}$: $\coNP^\NP$.
    \item $C$-complete: hardest decision problems in class $C$.
    %\item A decision problem $L$ is $C$-hard if $L' \leq_p L$ for every $L'$ in class $C$.
    %\item A decision problem $L$ is $C$-complete if $L$ is in class $C$ and $L$ is $C$-hard.
  \end{enumerate}

  \vspace{-0.3cm}

  \begin{figure}[ht!]
    \centering
      \includegraphics[width=0.5\textwidth]{figs/Preliminary/comp_diagram.pdf}
    \caption{Computational complexity diagram}
  \end{figure}
}

\frameT{Complexity Results on PLP-trees} {
  \begin{figure}[!ht]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
      \centering
      \begin{tabular}[0.45\textwidth]{ | c | c | c | }
        \hline
           & UP & CP \\
        \hline
        UI & P & P\\
        \hline
        CI & NPC\footnotemark & P  \\
        \hline
      \end{tabular}
      \caption{\tsc{ConsLearn}}
    \end{subfigure}
      \footnotetext{\scriptsize Booth et al., \tit{Learning Conditionally Lexicographic
            Preference Relations}, 2010.}
    \begin{subfigure}[b]{0.45\textwidth}
      \centering
      \begin{tabular}[0.45\textwidth]{ | c | c | c | }
        \hline
           & UP & CP \\
        \hline
        UI & NPC & NPC \\
        \hline
        CI & NPC & NPC \\
        \hline
      \end{tabular}
      \caption{\tsc{SmallLearn}}
    \end{subfigure} \\
    \begin{subfigure}[b]{0.45\textwidth}
      \centering
      \begin{tabular}[0.45\textwidth]{ | c | c | c | }
        \hline
           & UP & CP \\
        \hline
        UI & NPC\footnotemark & NPC \\
        \hline
        CI & NPC & NPC \\
        \hline
      \end{tabular}
      \caption{\tsc{MaxLearn}}
    \end{subfigure}
    \caption{Complexity results for learning PLP-trees}
  \end{figure}
  \footnotetext{\scriptsize Schmitt and Martignon, \tit{On the Complexity of
            Learning Lexicographic Strategies}, 2006.}
}

\frameT{Partial Lexicographic Preference Trees (PLP-Tree)}{
  \begin{figure}[ht!]
    \centering
      \includegraphics[width=0.4\textwidth]{figs/Cars/uiuptree.png}
    \caption{Unconditional Importance \& Unconditional Preference (UIUP)}
  \end{figure}
}

\frameT{Partial Lexicographic Preference Trees (PLP-Tree)}{
  \begin{figure}[ht!]
    \centering
      \includegraphics[width=0.65\textwidth]{figs/Cars/uicptree.png}
    \caption{UICP with at most 1 parent (UICP-1)}
  \end{figure}
}

\frameT{Partial Lexicographic Preference Trees (PLP-Tree)}{
  \begin{figure}[ht!]
    \centering
      \includegraphics[width=0.9\textwidth]{figs/Cars/ciuptree.png}
    \caption{CIUP with 1 split at the root (CIUP-1)}
  \end{figure}
}

\frameT{Partial Lexicographic Preference Trees (PLP-Tree)}{
  \begin{figure}[ht!]
    \centering
      \includegraphics[width=0.9\textwidth]{figs/Cars/cicptree.png}
    \caption{Simple CICP (SCICP)}
  \end{figure}
}

\frameT{Experimental Results: CarEvaluation\footnotetext{
\tiny \url{http://www.cs.uky.edu/~liu/preflearnlib.php}}
}
{
	\begin{center}
		\#attributes:6, \#outcomes:1728, \#examples:682721
	\end{center}

  \begin{figure}
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=0.95\textwidth]{figs/PrefLearnResults/MatLabOutput/CarEvaluation_Trees_X_MH.pdf}
      \caption{Compare exact \& greedy heuristic}
    \end{subfigure}
    \begin{subfigure}[b]{0.48\textwidth}
      \centering
      \includegraphics[width=0.95\textwidth]{figs/PrefLearnResults/MatLabOutput/CarEvaluation_Trees_MH.pdf}
      \caption{Greedy heuristic}
    \end{subfigure}

    \caption{Learning curves solving \tsc{MaxLearn}}
  \end{figure}

	
}

%\frameT{Preference Forests (P-Forests)}{
%	\begin{enumerate}
%		\item A \tit{preference forest} $F$ is a collection of PLP-trees
%					$F = \{T_1,\ldots,T_n\}$.
%		\item Denote by $N_F(o_1,o_2)=|\{T \in F:o_1 \succ_T o_2\}|$.
%		\item Given a preference forest $F$, and two outcomes $o_1$ and $o_2$, 
%					we say that $o_1 \succ_F^\Maj o_2$ iff $N_F(o_1,o_2)>N_F(o_2,o_1)$,
%					and that $o_1 \approx_F^\Maj o_2$ iff $N_F(o_1,o_2)=N_F(o_2,o_1)$.
%		\begin{itemize}
%			\item Pro: intuitive, decided in polynomial time.
%			\item Con: Condorcet paradox.
%			\item Other aggregating rules: positional scoring rules, Copeland's method, etc.
%		\end{itemize}
%	\end{enumerate}
%}
%
%\frameT{Experimental Results on P-Forests}{
%  \begin{figure}[ht!]
%    \centering
%      \includegraphics[width=0.7\textwidth]{figs/PrefLearnResults/Forests/X_MH/CarEvaluation.png}
%    \caption{Learning UIUP using ASP and greedy heuristic}
%  \end{figure}
%}
%
%\frameT{Experimental Results on P-Forests}{
%  \begin{figure}[ht!]
%    \centering
%      \includegraphics[width=0.7\textwidth]{figs/PrefLearnResults/Forests/MH/CarEvaluation.png}
%    \caption{Learning all four classes using greedy heuristic}
%  \end{figure}
%}
